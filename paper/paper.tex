\documentclass[11pt]{article}
\usepackage{fontspec}
\usepackage{ngerman}
\usepackage[top=3cm,left=3.5cm,right=3.5cm,bottom=3cm]{geometry}

\usepackage{listings}

\setromanfont{Charis SIL}
\setmonofont{Courier 10 Pitch}

\title{Control-Flow Integrity Checking}
\author{Hermann Loose}

\begin{document}

\maketitle

\section{Einführung}

% FIXME(hermannloose): Doofer Satzanfang.
Unerlaubter Kontrollfluss in Programmen stellt ein Problem sowohl für die
Sicherheit der Rechnersysteme auf denen diese Programme laufen als auch für die
Verlässlichkeit der von ihnen ausgeführten Berechnungen dar.

% Blah blah?
Es werden in der Folge zwei Verfahren betrachtet, die sich jeweils einem dieser
beiden Aspekte widmen und einander dabei in der Vorgehensweise zum Teil sehr
ähnlich sind.

\section{Control-Flow Integrity}

Das in \cite{abadi-2005-control-msr} vorgestellte Verfahren \emph{Control-Flow
Integrity} (CFI) zielt darauf ab, Angriffe zu verhindern, die auf dem Verlassen
des erlaubten Kontrollflusses in einem Programm aufbauen. Beispielhaft werden
stackbasierte Pufferüberläufe und darauf fußende Techniken, heapbasierte
\emph{jump-to-}\texttt{libc}-Angriffe sowie \emph{pointer subterfuge}-Angriffe
genannt.

Die Autoren argumentieren, dass viele der bisher gegen solche Angriffe
eingesetzten Mechanismen in ihrer Wirksamkeit beschränkt seien, da ihnen ein
realistisches Angreifermodell fehlen würde und sie sich selten auf formale
Schlüsse und häufig auf verborgene Annahmen stützten.

Die Antwort auf diese Probleme seien einfach verständliche Verfahren mit
dennoch umfassenden Garantien gegenüber starken Angreifern. Zudem sollten
praxistaugliche Techniken möglichst auf existierenden Code bzw. sogar auf
existierende Binärdateien anwendbar sein.

CFI als softwarebasierte Lösung wurde von den Autoren für Windows auf der x86
Architektur entwickelt und getestet; die Möglichkeit einer
Hardwareimplementierung von CFI wird hierbei kurz angesprochen, aber für die
nähere Zukunft als unwahrscheinlich bewertet. Ergänzend dazu wurde CFI in
\cite{abadi-2005-theory-fmse} für ein vereinfachtes Maschinenmodel
formalisiert.

\subsection{Grundlagen}

Das Angreifermodell für CFI beschreibt einen Angreifer, welcher „volle
Kontrolle über das Datensegment des ausführenden Programms besitzt“. Zusätzlich
wird die Möglichkeit zugelassen, dass der Angreifer bereits die Kontrolle über
ein anderes Modul oder einen anderen Thread im Adressraum besitzt. Als
tatsächliches Problem für die garantierte Einhaltung des erlaubten
Kontrollflusses identifizieren die Autoren daraufhin all die
Kontrollflusstransfers, deren Ziel im Programm erst zur Laufzeit bestimmt wird,
schließlich hat ein solcher Angreifer auf Transfers mit konstantem Ziel, wie
z.B. direkte Funktionsaufrufe, keinen Einfluss.

Um die Anwendung von CFI für existierende Software zu ermöglichen, wählten die
Autoren den Weg der Binärinstrumentierung von bereits übersetzten Programmen.
Durchgeführt wurde diese Instrumentierung mittels \emph{Vulcan}
\cite{edwards-vulcan}, von den Autoren als „reifes, state-of-the-art
Instrumentierungssystem für x86 Binärdateien“ beschrieben.

% TODO(hermannloose): Zur besseren Übersicht gerechtfertigt?
\subsubsection{Kontrollflussgraph}

Ausgangspunkt für das Verfahren ist ein \emph{Kontrollflussgraph} (CFG). Die
Knoten dieses Graphen bezeichnen sogenannte \emph{basic blocks}—Codeabschnitte
mit linearem Kontrollfluss ohne dynamische Transfers. Die gerichteten Kanten
des Graphen geben erlaubten Kontrollfluss zwischen diesen Knoten an.

Die erste Instruktion eines Knotens stellt ein erlaubtes Ziel für Transfers aus
den Startknoten der Eingangskanten dar. Am Ende des Knotens steht jeweils eine
Instruktion, welche ebenfalls den Kontrollfluss zur Laufzeit dynamisch bestimmt
und deren mögliche Ziele die Endknoten der ausgehenden Kanten sind.

% TODO(hermannloose): Holpriger Absatz, überarbeiten!
Mit Vorgriff auf die spätere Implementierung erfolgt zudem die Annahme, dass
Knoten, deren Eingangskanten gemeinsame Startknoten haben, äquivalente Ziele
darstellen, d.h. auf der Knotenmenge des Graphen ergeben sich
Äquivalenzklassen. Die Implikationen dieser Forderung werden später beleuchtet.
% FIXME(hermannloose): "Implikationen bezüglich was?" -> ausführen?

Die Autoren führen verschiedene Möglichkeiten für die Definition eines solchen
CFGs an, wobei sie sich für ihre Experimente auf CFGs konzentrieren, die durch
statische Analyse von Binärdateien gewonnen wurden, ebenfalls mittels Vulcan.

% TODO(hermannloose): An welcher Stelle Theorie einbauen?

\subsection{Instrumentierung}

Liegt ein solcher CFG vor, muss demnach zur Laufzeit vor Kontrollflusstransfers
mit dynamisch bestimmtem Ziel sichergestellt werden, dass vom aktuellen Knoten
zum jeweiligen Zielknoten eine Kante im CFG existiert.

Dazu wird jeder Äquivalenzklasse von Zielknoten im CFG eine ID zugewiesen und
direkt vor jedem Zielknoten im Codesegment eingefügt. Vor dem Transfer kann
daraufhin überprüft werden, ob die ID am aktuellen Ziel—dessen Adresse sich
z.B. in einem Register befindet—mit der ID der für diese Instruktion zulässigen
Ziele übereinstimmt.

Diese einleitende Betrachtung erfolgt unter Verwendung von erdachten
Instruktionen für Funktionsaufrufe und –rückkehr, welche jeweils die zulässige
Ziel-ID als Operand erhalten, sowie einer effektfreien Label-Instruktion, deren
Operand die ID des Knotens ist, welcher mit diesem Label versehen wird.

An dieser Stelle identifizieren die Autoren als Problem, dass mit dieser
Vorgehensweise nicht sichergestellt werden kann, dass Funktionen ausschließlich
zu ihrem jüngsten Aufrufort zurückkehren können. Es erfolgt der Verweis auf die
spätere Beschreibung eines auf CFI aufbauenden Verfahrens, welches diese
Beschränkung ermöglicht.

Die Autoren evaluieren in der Folge zwei konkrete Möglichkeiten der
Instrumentierung von Funktionsaufrufen.

\lstset{
  language=[x86masm]Assembler,
  basicstyle=\ttfamily\small,
  frame=lines
}

\begin{lstlisting}[title=Quelle]
  81 39 78 56 34 12  cmp  [ecx], 12345678h  ; comp ID & dst
  75 13              jne  error_label       ; if != fail
  8D 49 04           lea  ecx, [ecx+4]      ; skip ID at dst
  FF E1              jmp  ecx               ; jump to dst
\end{lstlisting}

\begin{lstlisting}[title=Ziel]
  78 56 34 12        ; data 12345678h       ; ID
  8B 44 24 04        mov  eax, [esp+4]      ; dst
  ...
\end{lstlisting}

Im ersten Fall stehen die Bytes der ID eines möglichen Ziels als Daten vor
diesem im Codesegment, Zieladressen von Kontrollflusstransfers zeigen jeweils
auf den Beginn dieser IDs. Der ID-Check an der Quelle vergleicht den Wert an
der Zieladresse mit einer als Immediate-Operand vorliegenden zulässigen ID.
% FIXME(hermannloose): Sehr holpriger Satz.
% FIXME(hermannloose): Eigentlich hier noch nicht konkret, da theoretische Betrachungen.
Schlägt dieser Vergleich fehl, erfolgt der Programmabbruch, mit einem von den
Autoren nicht weiter spezifizierten „Windows-Mechanismus zum Melden von
Sicherheitsverstößen“.

Als Problem wird bei dieser Methode angeführt, dass die Bytes der ID im
Codesegment sowohl am eigentlichen Ziel als auch in den Instruktionen des
ID-Checks vorkommen. Damit stellt die unmittelbar auf die Vergleichsoperation
folgende Instruktion—im Beispiel \texttt{jne error\_label}, zur
Fehlerbehandlung, was sich durch Präparieren der Prozessorflags umgehen
lässt—ein unerwartetes, gültiges Ziel dar.

\begin{lstlisting}[title=Quelle]
  B8 77 56 34 12     mov  eax, 12345677h    ; load ID-1
  40                 inc  eax               ; add 1 for ID
  39 41 04           cmp  [ecx+4], eax      ; compare w/ dst
  75 13              jne  error_label       ; if != fail
  FF E1              jmp  ecx               ; jump to label
\end{lstlisting}

\begin{lstlisting}[title=Ziel]
  3E 0F 18 05        prefetchnta            ; label
  78 56 34 12           [12345678h]         ;    ID
  8B 44 24 04        mov  eax, [esp+4]      ; dst
  ...
\end{lstlisting}

% TODO(hermannloose): Diese Variante wird von den Autoren später offensichtlich
% nicht verwendet.
Die zweite Herangehensweise löst diese Situation durch das Laden von ID–1 in
ein Register, nachfolgendes Inkrementieren und den Vergleich der ID am Ziel mit
dem enstandenden Wert.

\subsection{Annahmen}

Die Autoren setzen für den Einsatz von CFI drei Annahmen voraus:

\begin{description}

  \item [UNQ] \emph{Unique IDs:} „Nach der Instrumentierung dürfen die als IDs
  gewählten Bitmuster nirgendwo im Codesegment vorkommen außer in IDs und
  ID-Checks.“

  Die Autoren schlagen einen mindestens 32 Bit großen Schlüsselraum für die
  Wahl von IDs vor, um diese Annahme zu gewährleisten.

  \item [NWC] \emph{Non-Writable Code:} „Es darf dem Programm nicht möglich
  sein, das Codesegment zur Laufzeit zu verändern. Ansonsten wäre es einem
  Angreifer möglich, CFI z.B. durch das Überschreiben eines ID-Checks zu
  umgehen.“

  Während dies auf den meisten aktuellen Systemen gilt, weisen die Autoren auf
  problematische Fälle wie das Laden dynamisch gelinkter Bibliotheken und
  Codegenerierung zur Laufzeit hin.

  \item [NXD] \emph{Non-Executable Data:} „Es darf dem Programm nicht möglich
  sein, Daten als Code auszuführen. Ansonsten könnte ein Angreifer die
  Ausführung von Daten, welche mit der korrekten ID versehen sind, anstoßen.“

\end{description}

Es folgen einige Betrachtungen zum Verhalten des Systems, falls eine oder
mehrere Annahmen nicht gelten.

\subsection{Messungen}

Die in \cite{abadi-2009-control-tissec} diskutierten Messungen beziehen auf
bekannte Benchmarks aus dem SPEC-Paket. Sie wurden auf einem Pentium 4 x86 mit
1.8GHz und 512MB RAM unter Verwendung von Windows XP SP2 im \emph{Safe Mode},
bei dem ein Großteil der Dienste und Kernelmodule deaktiviert ist,
durchgeführt. Die untersuchten Programme wurden in Microsoft Visual C++ 7.1 mit
allen verfügbaren Optimierungen compiliert.

Die ermittelten Werte stellen jeweils den Durchschnitt von drei Durchläufen
dar, die Standardabweichung von weniger als einem Prozent wurde von den Autoren
als vernachlässigbar angesehen.

Der durchschnittliche Zuwachs an Größe für ein mit CFI instrumentiertes
Programm belief sich auf 8\%. Die Laufzeit der instrumentierten Programme stieg
um durchschnittlich 16\%. Die Autoren bewerten diesen Overhead als akzeptabel
und verweisen—ohne weitere Ausführungen—auf Möglichkeiten der Optimierung für
die x86 Implementierung von CFI.

% Kritik: wenig sicherheitsrelevante Ergebnisse, bereits 2004 im ersten Entwurf
% nur Sektion für Performancemessungen angelegt!

% FIXME(hermannloose): Besseren Titel finden.
\subsection{CFI als Grundlage für andere Verfahren}

% TODO(hermannloose): Zitate für IRMs und SMAC?
Aufgrund seiner Garantien für den Kontrollfluss von Programmen kann CFI zudem
als Grundlage für den Einsatz bzw. die Optimierung und Vereinfachung einer
Reihe anderer, ebenfalls softwarebasierter Mechanismen dienen. Die in
\cite{abadi-2009-control-tissec} beleuchteten sind \emph{Inlined Reference
Monitors} (IRMs) und \emph{Software Memory Access-Control} (SMAC).

% wie erkläre ich die zwei Verfahren, ohne hier einfach das Paper übersetzt zu
% reproduzieren? (oder ist das legitim?)

% FIXME(hermannloose): Anderen Titel finden.
% Ausblick nach sieben Jahren ist etwas müßig.
\subsection{Ausblick}

% Kritik: an dem Thema hat sich seit 2005 nichts getan
\cite{abadi-2009-control-tissec} erschien zuerst im Februar 2005 als Technical
Report von Microsoft Research \cite{abadi-2005-control-msr}. Spätere
Veröffentlichungen 2005 und 2007 sind inhaltlich identisch. Zum Problem des
Umgangs mit selbstmodifizierendem Code und Codegenerierung zur Laufzeit erfolgt
in \cite{abadi-2005-control-msr} der Verweis „we are working on […] handling
runtime code generation and other dynamic additions of code“, seit 2007 und in
\cite{abadi-2009-control-tissec} lautet diese Stelle nunmehr „we have
considered working on […] handling runtime code generation and other dynamic
additions of code“, was nahelegt, dass hier kein weiterer Fortschritt erfolgt
ist. % TODO(hermannloose): Zitate checken.

% beleuchten: ist Overhead ein Problem?

\section{Control-Flow~Checking by Software~Signatures}

Im Gegensatz zu CFI beschäftigt sich das 2002 in \cite{oh-2002-control}
beschriebene Verfahren \emph{Control-Flow Checking by Software Signatures}
(CFCSS) mit der Erkennung von unerlaubtem Kontrollfluss, nachdem dieser bereits
aufgetreten ist. Das Augenmerk liegt dabei auf transienten oder permanenten
Hardwarefehlern als Auslöser. Die Autoren identifizieren dadurch in der Folge
unentdeckt bleibende, da nicht von Programmabstürzen begleitete Verfälschungen
von Ergebnissen als Hauptproblem.

Der Ausgangspunkt ist wie bei CFI eine softwarebasierte Lösung. Als Motivation
wird das Stanford \emph{Advanced Research and Global Observation Satellite}
(ARGOS) Projekt angeführt. Das auf diesem Satelliten befindliche
\emph{Unconventional Stellar Aspect} (USA)
Experiment\footnote{http://xweb.nrl.navy.mil/usa/publications/usa-xrb.html}
trug neben einem strahlungsfesten RH-3000 Single-Board-Computer mit
verschiedenen Möglichkeiten zur Erkennung und Korrektur von Hardwarefehlern ein
äquivalentes Board aus herkömmlichen Komponenten zum
Vergleich.\cite{argos-2002-lessons}. Für letzteres beschränkten sich
Fehlererkennung und –behebung auf Softwaremethoden, einschließlich CFCSS.

\subsection{Konzept}

\subsection{Simulationsergebnisse}

\pagebreak
%\section{Quellen}
\bibliographystyle{unsrt}
\bibliography{paper}

\end{document}
