\documentclass[11pt]{article}
\usepackage{fontspec}
\usepackage{ngerman}
\usepackage[top=3cm,left=3.5cm,right=3.5cm,bottom=3cm]{geometry}

\setromanfont{Charis SIL}

\title{Control-Flow Integrity Checking}
\author{Hermann Loose}

\begin{document}

\maketitle

\section{Einführung}

% FIXME(hermannloose): Doofer Satzanfang.
Unerlaubter Kontrollfluss in Programmen stellt ein Problem sowohl für die
Sicherheit der Rechnersysteme auf denen diese Programme laufen als auch für die
Verlässlichkeit der von ihnen ausgeführten Berechnungen dar.

% Blah blah?
Es werden in der Folge zwei Verfahren betrachtet, die sich jeweils einem dieser
beiden Aspekte widmen und einander dabei in der Vorgehensweise zum Teil sehr
ähnlich sind.

\section{Control-Flow Integrity}

Das in \cite{abadi-2005-control-msr} vorgestellte Verfahren \emph{Control-Flow
Integrity} (CFI) zielt darauf ab, Angriffe zu verhindern, die auf dem Verlassen
des erlaubten Kontrollflusses in einem Programm aufbauen. Beispielhaft werden
stackbasierte Pufferüberläufe und darauf fußende Techniken, heapbasierte
\emph{jump-to-}\texttt{libc}-Angriffe sowie \emph{pointer subterfuge}-Angriffe
genannt.

Die Autoren argumentieren, dass viele der bisher gegen solche Angriffe
eingesetzten Mechanismen in ihrer Wirksamkeit beschränkt seien, da ihnen ein
realistisches Angreifermodell fehlen würde und sie sich selten auf formale
Schlüsse und häufig auf verborgene Annahmen stützten.

Die Antwort auf diese Probleme seien einfach verständliche Verfahren mit
dennoch umfassenden Garantien gegenüber starken Angreifern. Zudem sollten
praxistaugliche Techniken möglichst auf existierenden Code bzw. sogar auf
existierende Binärdateien anwendbar sein.

CFI als softwarebasierte Lösung wurde von den Autoren für Windows auf der x86
Architektur entwickelt und getestet; die Möglichkeit einer
Hardwareimplementierung von CFI wird hierbei kurz angesprochen, aber für die
nähere Zukunft als unwahrscheinlich bewertet. Ergänzend dazu wurde CFI in
\cite{abadi-2005-theory-fmse} für ein vereinfachtes Maschinenmodel
formalisiert.

\subsection{Grundlagen}

Das Angreifermodell für CFI beschreibt einen Angreifer, welcher „volle
Kontrolle über das Datensegment des ausführenden Programms besitzt“. Zusätzlich
wird die Möglichkeit zugelassen, dass der Angreifer bereits die Kontrolle über
ein anderes Modul oder einen anderen Thread im Adressraum besitzt. Als
tatsächliches Problem für die garantierte Einhaltung des erlaubten
Kontrollflusses identifizieren die Autoren daraufhin all die
Kontrollflusstransfers, deren Ziel im Programm erst zur Laufzeit bestimmt wird,
schließlich hat ein solcher Angreifer auf Transfers mit konstantem Ziel, wie
z.B. direkte Funktionsaufrufe, keinen Einfluss.

Um die Anwendung von CFI für existierende Software zu ermöglichen, wählten die
Autoren den Weg der Binärinstrumentierung von bereits übersetzten Programmen.
Durchgeführt wurde diese Instrumentierung mittels \emph{Vulcan}
\cite{edwards-vulcan}, von den Autoren als „reifes, state-of-the-art
Instrumentierungssystem für x86 Binärdateien“ beschrieben.

% TODO(hermannloose): Zur besseren Übersicht gerechtfertigt?
\subsubsection{Kontrollflussgraph}

Ausgangspunkt für das Verfahren ist ein \emph{Kontrollflussgraph} (CFG). Die
Knoten dieses Graphen bezeichnen sogenannte \emph{basic blocks}—Codeabschnitte
mit linearem Kontrollfluss ohne dynamische Transfers. Die gerichteten Kanten
des Graphen geben erlaubten Kontrollfluss zwischen diesen Knoten an.

Die erste Instruktion eines Knotens stellt ein erlaubtes Ziel für Transfers aus
den Knoten der Eingangskanten dar. Am Ende des Knotens steht jeweils eine
Instruktion, welche ebenfalls den Kontrollfluss zur Laufzeit dynamisch bestimmt
und deren mögliche Ziele durch die ausgehenden Kanten bestimmt sind.

Die Autoren führen verschiedene Möglichkeiten für die Definition eines solchen
CFGs an, wobei sie sich für ihre Experimente auf CFGs konzentrieren, die durch
statische Analyse von Binaries gewonnen wurden.



% TODO(hermannloose): An welcher Stelle Theorie einbauen?

% FIXME(hermannloose): Artet evtl. in Kopie aus.
\subsection{Instrumentierung}

% FIXME(hermannloose): Artet evtl. in Kopie aus.
\subsection{Annahmen}

Die Autoren setzen für den Einsatz von CFI drei Annahmen voraus:

\begin{description}

  \item [UNQ] \emph{Unique IDs:} „Nach der Instrumentierung dürfen die als IDs
  gewählten Bitmuster nirgendwo im Codesegment vorkommen außer in IDs und
  ID-Checks.“

  Die Autoren schlagen einen mindestens 32 Bit großen Schlüsselraum für die
  Wahl von IDs vor, um diese Annahme zu gewährleisten.

  \item [NWC] \emph{Non-Writable Code:} „Es darf dem Programm nicht möglich
  sein, das Codesegment zur Laufzeit zu verändern. Ansonsten wäre es einem
  Angreifer möglich, CFI z.B. durch das Überschreiben eines ID-Checks zu
  umgehen.“

  Während dies auf den meisten aktuellen Systemen gilt, weisen die Autoren auf
  problematische Fälle wie das Laden dynamisch gelinkter Bibliotheken und
  Codegenerierung zur Laufzeit hin.

  \item [NXD] \emph{Non-Executable Data:} „Es darf dem Programm nicht möglich
  sein, Daten als Code auszuführen. Ansonsten könnte ein Angreifer die
  Ausführung von Daten, welche mit der korrekten ID versehen sind, anstoßen.“

\end{description}

Es folgen einige Betrachtungen zum Verhalten des Systems, falls eine oder
mehrere Annahmen nicht gelten.

\subsection{Messungen}

Die in \cite{abadi-2009-control-tissec} diskutierten Messungen beziehen auf
bekannte Benchmarks aus dem SPEC-Paket. Sie wurden auf einem Pentium 4 x86 mit
1.8GHz und 512MB RAM unter Verwendung von Windows XP SP2 im \emph{Safe Mode},
bei dem ein Großteil der Dienste und Kernelmodule deaktiviert ist,
durchgeführt. Die untersuchten Programme wurden in Microsoft Visual C++ 7.1 mit
allen verfügbaren Optimierungen compiliert.

Die ermittelten Werte stellen jeweils den Durchschnitt von drei Durchläufen
dar, die Standardabweichung von weniger als einem Prozent wurde von den Autoren
als vernachlässigbar angesehen.

Der durchschnittliche Zuwachs an Größe für ein mit CFI instrumentiertes
Programm belief sich auf 8\%. Die Laufzeit der instrumentierten Programme stieg
um durchschnittlich 16\%. Die Autoren bewerten diesen Overhead als akzeptabel
und verweisen—ohne weitere Ausführungen—auf Möglichkeiten der Optimierung für
die x86 Implementierung von CFI.

% Kritik: wenig sicherheitsrelevante Ergebnisse, bereits 2004 im ersten Entwurf
% nur Sektion für Performancemessungen angelegt!

% FIXME(hermannloose): Besseren Titel finden.
\subsection{CFI als Grundlage für andere Verfahren}

% TODO(hermannloose): Zitate für IRMs und SMAC?
Aufgrund seiner Garantien für den Kontrollfluss von Programmen kann CFI zudem
als Grundlage für den Einsatz bzw. die Optimierung und Vereinfachung einer
Reihe anderer, ebenfalls softwarebasierter Mechanismen dienen. Die in
\cite{abadi-2009-control-tissec} beleuchteten sind \emph{Inlined Reference
Monitors} (IRMs) und \emph{Software Memory Access-Control} (SMAC).

% wie erkläre ich die zwei Verfahren, ohne hier einfach das Paper übersetzt zu
% reproduzieren? (oder ist das legitim?)

% FIXME(hermannloose): Anderen Titel finden.
% Ausblick nach sieben Jahren ist etwas müßig.
\subsection{Ausblick}

% Kritik: an dem Thema hat sich seit 2005 nichts getan
\cite{abadi-2009-control-tissec} erschien zuerst im Februar 2005 als Technical
Report von Microsoft Research \cite{abadi-2005-control-msr}. Spätere
Veröffentlichungen 2005 und 2007 sind inhaltlich identisch. Zum Problem des
Umgangs mit selbstmodifizierendem Code und Codegenerierung zur Laufzeit erfolgt
in \cite{abadi-2005-control-msr} der Verweis „we are working on […] handling
runtime code generation and other dynamic additions of code“, seit 2007 und in
\cite{abadi-2009-control-tissec} lautet diese Stelle nunmehr „we have
considered working on […] handling runtime code generation and other dynamic
additions of code“, was nahelegt, dass hier kein weiterer Fortschritt erfolgt
ist. % TODO(hermannloose): Zitate checken.

% beleuchten: ist Overhead ein Problem?

\section{Control-Flow~Checking by Software~Signatures}

Im Gegensatz zu CFI beschäftigt sich das 2002 in \cite{oh-2002-control}
beschriebene Verfahren \emph{Control-Flow Checking by Software Signatures}
(CFCSS) mit der Erkennung von unerlaubtem Kontrollfluss, nachdem dieser bereits
aufgetreten ist. Das Augenmerk liegt dabei auf transienten oder permanenten
Hardwarefehlern als Auslöser. Die Autoren identifizieren dadurch in der Folge
unentdeckt bleibende, da nicht von Programmabstürzen begleitete Verfälschungen
von Ergebnissen als Hauptproblem.

Der Ausgangspunkt ist wie bei CFI eine softwarebasierte Lösung. Als Motivation
wird das Stanford \emph{Advanced Research and Global Observation Satellite}
(ARGOS) Projekt angeführt. Das auf diesem Satelliten befindliche
\emph{Unconventional Stellar Aspect} (USA)
Experiment\footnote{http://xweb.nrl.navy.mil/usa/publications/usa-xrb.html}
trug neben einem strahlungsfesten RH-3000 Single-Board-Computer mit
verschiedenen Möglichkeiten zur Erkennung und Korrektur von Hardwarefehlern ein
äquivalentes Board aus herkömmlichen Komponenten zum
Vergleich.\cite{argos-2002-lessons}. Für letzteres beschränkten sich
Fehlererkennung und –behebung auf Softwaremethoden, einschließlich CFCSS.

\subsection{Konzept}

\subsection{Simulationsergebnisse}

\pagebreak
%\section{Quellen}
\bibliographystyle{unsrt}
\bibliography{paper}

\end{document}
